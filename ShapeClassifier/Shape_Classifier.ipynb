{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28031a1",
   "metadata": {},
   "source": [
    "# Shape Classifier: Circles, Squares, and Triangles\n",
    "\n",
    "A Jupyter Notebook to demonstrate the training and evaluation of a CNN model to classify synthetic images of geometric shapes.\n",
    "\n",
    "**Project Structure Note:** In adherence to the project requirement for `clean, modular, and well-organized code,` complex helper functions for data generation and visualization are encapsulated in the `ShapeClassifier/utils/` directory. This keeps the main notebook focused on the core machine learning workflow: configuration, data loading, model definition, training, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88344dde",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration\n",
    "\n",
    "This section handles all the initial setup for the project:\n",
    "*   Importing essential libraries.\n",
    "*   Defining constants, hyperparameters, and file paths.\n",
    "*   Setting up reproducibility seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a1ea52",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# --- Add Project Root to `sys.path` ---\n",
    "# This allows us to import from the 'ShapeClassifier/utils' directory,\n",
    "# no matter where the notebook is run from.\n",
    "# The project root is two levels up from the current notebook's directory.\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(\"System path configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4522ceb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Path Constants ---\n",
    "# Define paths relative to the project root for robustness.\n",
    "ARTIFACTS_DIR = os.path.join(PROJECT_ROOT, '..', 'shape-classifier-artifacts')\n",
    "DATASET_DIR = os.path.join(ARTIFACTS_DIR, 'shape-classifier-datasets', 'ShapeClassifier')\n",
    "MODEL_CHECKPOINT_DIR = os.path.join(ARTIFACTS_DIR, 'shape-classifier-models', 'ShapeClassifier')\n",
    "MODEL_CHECKPOINT_PATH = os.path.join(MODEL_CHECKPOINT_DIR, 'best_model_checkpoint.pth')\n",
    "\n",
    "# --- Universal Constants ---\n",
    "CLASSES = ['circle', 'square', 'triangle']\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- For Reproducibility ---\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Sets the seed for random, numpy, and torch for reproducible results.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# --- Initial Setup ---\n",
    "# Ensure the directory for saving model checkpoints exists.\n",
    "os.makedirs(MODEL_CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "print(f\"Device set to: {DEVICE.upper()}\")\n",
    "print(f\"Dataset directory verified at: {os.path.abspath(DATASET_DIR)}\")\n",
    "print(f\"Model checkpoint directory verified at: {os.path.abspath(MODEL_CHECKPOINT_DIR)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cb0336",
   "metadata": {},
   "source": [
    "## 2. Data Generation & Loading\n",
    "\n",
    "This section covers preparing the data for the model. It includes:\n",
    "*   An optional step to regenerate the entire dataset from scratch.\n",
    "*   Defining a custom PyTorch `Dataset` class to load the images.\n",
    "*   Applying necessary transformations.\n",
    "*   Creating `DataLoader`s to feed data to the model in batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b9db0",
   "metadata": {},
   "source": [
    "## 3. Model Architecture\n",
    "\n",
    "Here, we define the architecture of our Convolutional Neural Network (CNN) and provide the justification for this choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba7d2c",
   "metadata": {},
   "source": [
    "## 4. Training the Model\n",
    "\n",
    "This section contains the logic for training the model, including:\n",
    "*   Defining the loss function and optimizer.\n",
    "*   Implementing the training and validation loops.\n",
    "*   Incorporating early stopping and model checkpointing to save the best-performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d5bcd",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "After training, we evaluate the model's performance on the unseen test set. This includes:\n",
    "*   Loading the best model checkpoint.\n",
    "*   Calculating final test accuracy.\n",
    "*   Visualizing a confusion matrix and sample predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cfd960",
   "metadata": {},
   "source": [
    "## 6. Analysis & Conclusion\n",
    "\n",
    "A final summary of the results, including:\n",
    "*   Plotting the training/validation curves.\n",
    "*   Answering the project questions on learnings and potential improvements."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
