{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28031a1",
   "metadata": {},
   "source": [
    "# Shape Classifier: Circles, Squares, and Triangles\n",
    "\n",
    "A Jupyter Notebook to demonstrate the training and evaluation of a CNN model to classify synthetic images of geometric shapes.\n",
    "\n",
    "**Project Structure Note:** In adherence to the project requirement for `clean, modular, and well-organized code,` complex helper functions for data generation and visualization are encapsulated in the `ShapeClassifier/utils/` directory. This keeps the main notebook focused on the core machine learning workflow: configuration, data loading, model definition, training, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88344dde",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration\n",
    "\n",
    "This section handles all the initial setup for the project:\n",
    "*   Importing essential libraries.\n",
    "*   Defining constants, hyperparameters, and file paths.\n",
    "*   Setting up reproducibility seeds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17010b2",
   "metadata": {},
   "source": [
    "### 1.1. Path Configuration\n",
    "\n",
    "First, we set up the system path to ensure our utility scripts in the `ShapeClassifier/utils/` directory can be imported reliably. We also define the core paths for our project artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8a1ea52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 'c:\\Users\\gilda\\OneDrive\\Documents\\My_Projects\\AI_Based_Projects\\shape-classifier-interview\\shape-classifier-pytorch' to system path.\n",
      "Project Root: c:\\Users\\gilda\\OneDrive\\Documents\\My_Projects\\AI_Based_Projects\\shape-classifier-interview\\shape-classifier-pytorch\n",
      "Dataset Directory: c:\\Users\\gilda\\OneDrive\\Documents\\My_Projects\\AI_Based_Projects\\shape-classifier-interview\\shape-classifier-pytorch\\..\\shape-classifier-artifacts\\shape-classifier-datasets\\ShapeClassifier\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# We assume this notebook is run from its location in the 'ShapeClassifier' directory.\n",
    "# The project root is one level up.\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "    print(f\"Added '{PROJECT_ROOT}' to system path.\")\n",
    "\n",
    "# Define core paths relative to the project root for robustness.\n",
    "ARTIFACTS_DIR = os.path.join(PROJECT_ROOT, '..', 'shape-classifier-artifacts')\n",
    "DATASET_DIR = os.path.join(ARTIFACTS_DIR, 'shape-classifier-datasets', 'ShapeClassifier')\n",
    "MODEL_CHECKPOINT_DIR = os.path.join(ARTIFACTS_DIR, 'shape-classifier-models', 'ShapeClassifier')\n",
    "\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"Dataset Directory: {DATASET_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674cc40b",
   "metadata": {},
   "source": [
    "### 1.2. Library Imports\n",
    "\n",
    "Next, we import all the necessary libraries for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ff414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c377a5",
   "metadata": {},
   "source": [
    "### 1.3. Constants and Seeding\n",
    "\n",
    "We define key constants for our project and a function to set seeds for reproducibility. The seeding function is called in a separate cell to prevent it from being re-run unnecessarily when constants are changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4522ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to: CUDA\n"
     ]
    }
   ],
   "source": [
    "# --- Constants ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "CLASSES = ['circle', 'square', 'triangle']\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "MODEL_CHECKPOINT_PATH = os.path.join(MODEL_CHECKPOINT_DIR, 'best_model_checkpoint.pth')\n",
    "\n",
    "\n",
    "# --- Seeding Function ---\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Sets the seed for random, numpy, and torch for reproducible results.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Seed set to {seed}\")\n",
    "\n",
    "print(f\"Device set to: {DEVICE.upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370723aa",
   "metadata": {},
   "source": [
    "### 1.4. Initial Setup Execution\n",
    "\n",
    "Here we execute one-time setup commands: we set the global seed and ensure the directory for saving our model checkpoints exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a3130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Initial setup executed.\n"
     ]
    }
   ],
   "source": [
    "# Set the seed for the entire notebook session.\n",
    "set_seed(42)\n",
    "\n",
    "# Ensure the directory for saving model checkpoints exists.\n",
    "os.makedirs(MODEL_CHECKPOINT_DIR, exist_ok=True)\n",
    "print(\"Initial setup executed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cb0336",
   "metadata": {},
   "source": [
    "## 2. Data Generation & Loading\n",
    "\n",
    "This section covers preparing the data for the model. It includes:\n",
    "*   An optional step to regenerate the entire dataset from scratch.\n",
    "*   Defining a custom PyTorch `Dataset` class to load the images.\n",
    "*   Applying necessary transformations.\n",
    "*   Creating `DataLoader`s to feed data to the model in batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd19a0c3",
   "metadata": {},
   "source": [
    "### 2.1. Optional: Generate Dataset from Scratch\n",
    "\n",
    "This project is configured to use the pre-generated (or downloaded) dataset located in the `shape-classifier-artifacts` directory.\n",
    "\n",
    "However, if you wish to regenerate the entire dataset from scratch, you can set the `REGENERATE_DATA` flag in the cell below to `True`.\n",
    "\n",
    "**Warning:** This process will delete all existing data in the target directory and will take several minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9974de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping data generation. Using existing dataset.\n",
      "\n",
      "Dataset found at: c:\\Users\\gilda\\OneDrive\\Documents\\My_Projects\\AI_Based_Projects\\shape-classifier-interview\\shape-classifier-pytorch\\..\\shape-classifier-artifacts\\shape-classifier-datasets\\ShapeClassifier\n"
     ]
    }
   ],
   "source": [
    "from ShapeClassifier.utils.data_generator import generate_dataset\n",
    "\n",
    "# --- Configuration for Data Generation ---\n",
    "REGENERATE_DATA = False # Set to True to run the data generation process.\n",
    "\n",
    "# These parameters are used ONLY if REGENERATE_DATA is True.\n",
    "TOTAL_IMAGES_TO_GENERATE = 6000\n",
    "SPLIT_RATIOS = {'train': 0.7, 'validation': 0.15, 'test': 0.15}\n",
    "\n",
    "\n",
    "if REGENERATE_DATA:\n",
    "    # We call our imported function using the path constants defined in Section 1.\n",
    "    generate_dataset(\n",
    "        root_dir=DATASET_DIR,\n",
    "        total_images=TOTAL_IMAGES_TO_GENERATE,\n",
    "        # root_dir=os.path.join(DATASET_DIR, \"Delete\"),\n",
    "        # total_images=100,\n",
    "        splits=SPLIT_RATIOS,\n",
    "        shapes=CLASSES # Using the 'CLASSES' constant from Section 1\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping data generation. Using existing dataset.\")\n",
    "\n",
    "# Verify that the dataset directory exists.\n",
    "if not os.path.exists(DATASET_DIR):\n",
    "    print(\"\\nERROR: Dataset directory not found!\")\n",
    "    print(f\"Please run the project's download script or set REGENERATE_DATA to True.\")\n",
    "else:\n",
    "    print(f\"\\nDataset found at: {DATASET_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b632f874",
   "metadata": {},
   "source": [
    "### 2.2. PyTorch Dataset Class\n",
    "\n",
    "To load our data into PyTorch, we need to create a custom `Dataset` class. This class acts as a standardized interface and is responsible for two key things:\n",
    "1.  `__len__`: Telling PyTorch the total number of images in the dataset.\n",
    "2.  `__getitem__`: Providing the i-th item from the dataset, which consists of an image and its corresponding label, ready for the model.\n",
    "\n",
    "Our `ShapeDataset` class will scan a given directory (e.g., `train`, `validation`, or `test`), find all image paths, and infer the correct label from the subdirectory name (e.g., 'circle', 'square')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb3b5ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapeDataset class defined.\n"
     ]
    }
   ],
   "source": [
    "class ShapeDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading shape images.\"\"\"\n",
    "\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir (string): Directory with all the images, organized in subfolders by class.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(data_dir))\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Walk through the directory to gather image paths and labels\n",
    "        for cls_name in self.classes:\n",
    "            class_dir = os.path.join(data_dir, cls_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                self.image_paths.append(os.path.join(class_dir, img_name))\n",
    "                self.labels.append(self.class_to_idx[cls_name])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the image\n",
    "        img_path = self.image_paths[idx]\n",
    "        # Using .convert('L') ensures the image is loaded as single-channel grayscale\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        \n",
    "        # Get the label\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Apply transformations if they exist\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "print(\"ShapeDataset class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b9db0",
   "metadata": {},
   "source": [
    "## 3. Model Architecture\n",
    "\n",
    "Here, we define the architecture of our Convolutional Neural Network (CNN) and provide the justification for this choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446bccd3",
   "metadata": {},
   "source": [
    "### 2.3. Calculating Normalization Statistics for Z-Score Standardization\n",
    "\n",
    "A crucial step in preparing image data for a neural network is **normalization**. Normalization rescales the pixel values to a standard range, which helps the model's optimizer converge faster and more reliably. Without it, the large range of pixel values (0-255) can lead to unstable gradients during training.\n",
    "\n",
    "While a simple approach is to scale values to a fixed range like `[-1, 1]`, a more robust and widely-used technique is **Z-score standardization**. This method transforms the data so that it has a **mean of 0 and a standard deviation of 1**.\n",
    "\n",
    "The formula for each pixel is:\n",
    "$$ z = \\frac{x - \\mu}{\\sigma} $$\n",
    "where:\n",
    "- $x$ is the original pixel value\n",
    "- $\\mu$ (mu) is the mean of all pixel values in the dataset\n",
    "- $\\sigma$ (sigma) is the standard deviation of all pixel values\n",
    "\n",
    "To implement this, we must first calculate the true $\\mu$ and $\\sigma$ from our data.\n",
    "\n",
    "**Important:** We only ever calculate these statistics on the **training set**. The validation and test sets must remain \"unseen.\" Using statistics from them would be a form of data leakage, giving our model an unfair preview of the data it will be evaluated on.\n",
    "\n",
    "In the next cell, we create a temporary dataset with a simple `ToTensor()` transform to iterate through all training images and compute these two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47c5cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary dataset of the training data just for calculating the mean and std\n",
    "# We only need to convert images to tensors for this calculation.\n",
    "temp_train_dataset = ShapeDataset(\n",
    "    data_dir=os.path.join(DATASET_DIR, 'train'), \n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# Use a DataLoader to iterate through the dataset efficiently\n",
    "temp_loader = DataLoader(temp_train_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# Calculate mean and std\n",
    "mean = 0.\n",
    "std = 0.\n",
    "num_samples = 0\n",
    "\n",
    "print(\"Calculating mean and standard deviation from the training set...\")\n",
    "# Wrap the loader with tqdm for a progress bar\n",
    "for images, _ in tqdm(temp_loader, desc=\"Calculating Stats\"):\n",
    "    # Reshape images to (batch_size, num_pixels) and count samples\n",
    "    batch_samples = images.size(0)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    # Update mean and std\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.std(2).sum(0)\n",
    "    num_samples += batch_samples\n",
    "\n",
    "mean /= num_samples\n",
    "std /= num_samples\n",
    "\n",
    "print(f\"\\nCalculated Mean: {mean.item():.4f}\")\n",
    "print(f\"Calculated Std: {std.item():.4f}\")\n",
    "\n",
    "# --- Clean up temporary objects ---\n",
    "# We no longer need these, so we can free up memory.\n",
    "del temp_loader, temp_train_dataset\n",
    "print(\"\\nTemporary objects for calculation have been cleaned up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e399eba8",
   "metadata": {},
   "source": [
    "### 2.4. Defining the Final Image Transformation Pipelines\n",
    "\n",
    "Now that we have the exact mean and standard deviation of our training data, we can build our final transformation pipelines. We use `torchvision.transforms.Compose` to chain together multiple operations.\n",
    "\n",
    "Our pipeline will consist of two steps:\n",
    "1.  `transforms.ToTensor()`: This is a critical first step. It converts the PIL Image, which is a grid of pixels with values from `[0, 255]`, into a PyTorch FloatTensor. It also automatically scales the pixel values to a range of `[0.0, 1.0]`.\n",
    "2.  `transforms.Normalize(mean, std)`: This takes the `[0.0, 1.0]` tensor from the previous step and applies the Z-score formula ($z = (x - \\mu) / \\sigma$), using the `mean` and `std` we just calculated.\n",
    "\n",
    "We create two separate pipelines. Although they are identical in this case, it is good practice to distinguish between them. In more complex projects, the training pipeline might include additional data augmentation steps (like random rotations or flips) that should not be applied to the validation or test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114369cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the final transformations for our datasets using the calculated stats.\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'val_test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Data transformations defined with calculated mean and std.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d8dc41",
   "metadata": {},
   "source": [
    "### 2.3. Image Transformations\n",
    "\n",
    "Before an image can be processed by a neural network, it must be transformed. We define two separate transformation pipelines:\n",
    "1.  **For Training Data:** We apply standard transformations. (In other projects, this is often where data augmentation like random flips or rotations would be added, but we have already built robust augmentation into our data generator).\n",
    "2.  **For Validation & Test Data:** We only apply the essential transformations needed for the model to understand the input, without any augmentation.\n",
    "\n",
    "The key transformations are:\n",
    "-   `ToTensor()`: Converts the PIL Image (pixel values 0-255) into a PyTorch Tensor (values 0.0-1.0).\n",
    "-   `Normalize()`: Adjusts the pixel values to have a specific mean and standard deviation. Normalizing to a range of [-1.0, 1.0] helps the model train more stably. For a single-channel image, we use a mean of `0.5` and a standard deviation of `0.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd90deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations for our datasets.\n",
    "# For grayscale images, the mean and std are tuples with a single value.\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ]),\n",
    "    'val_test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Data transformations defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba7d2c",
   "metadata": {},
   "source": [
    "## 4. Training the Model\n",
    "\n",
    "This section contains the logic for training the model, including:\n",
    "*   Defining the loss function and optimizer.\n",
    "*   Implementing the training and validation loops.\n",
    "*   Incorporating early stopping and model checkpointing to save the best-performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d5bcd",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "After training, we evaluate the model's performance on the unseen test set. This includes:\n",
    "*   Loading the best model checkpoint.\n",
    "*   Calculating final test accuracy.\n",
    "*   Visualizing a confusion matrix and sample predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cfd960",
   "metadata": {},
   "source": [
    "## 6. Analysis & Conclusion\n",
    "\n",
    "A final summary of the results, including:\n",
    "*   Plotting the training/validation curves.\n",
    "*   Answering the project questions on learnings and potential improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shape-classifier-pytorch-cUSr_hTk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
